{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4],\n",
      "         [5, 6]]]) 3 torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor([[[1, 2], [3, 4], [5, 6]]])\n",
    "print(scalar, scalar.ndim, scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 18 16:43:01 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060        Off |   00000000:01:00.0  On |                  N/A |\n",
      "| 33%   32C    P8             N/A /  115W |     670MiB /   8188MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2723      G   /usr/lib/xorg/Xorg                            184MiB |\n",
      "|    0   N/A  N/A      2937      G   /usr/bin/gnome-shell                           50MiB |\n",
      "|    0   N/A  N/A      2987      G   /usr/bin/veyon-server                           2MiB |\n",
      "|    0   N/A  N/A      2999      G   /usr/bin/veyon-worker                           2MiB |\n",
      "|    0   N/A  N/A      3902      G   ...irefox/4793/usr/lib/firefox/firefox        175MiB |\n",
      "|    0   N/A  N/A      6277      G   ...erProcess --variations-seed-version         88MiB |\n",
      "|    0   N/A  N/A      7466      C   ...s/image_processing/.venv/bin/python        106MiB |\n",
      "|    0   N/A  N/A      7832      G   ...onEnabled --variations-seed-version         37MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing \n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.9521]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.7055], requires_grad=True))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "model.weight, model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7055],\n",
       "        [-0.6864],\n",
       "        [-0.6674],\n",
       "        [-0.6483],\n",
       "        [-0.6293],\n",
       "        [-0.6103],\n",
       "        [-0.5912],\n",
       "        [-0.5722],\n",
       "        [-0.5531],\n",
       "        [-0.5341],\n",
       "        [-0.5150],\n",
       "        [-0.4960],\n",
       "        [-0.4770],\n",
       "        [-0.4579],\n",
       "        [-0.4389],\n",
       "        [-0.4198],\n",
       "        [-0.4008],\n",
       "        [-0.3817],\n",
       "        [-0.3627],\n",
       "        [-0.3437],\n",
       "        [-0.3246],\n",
       "        [-0.3056],\n",
       "        [-0.2865],\n",
       "        [-0.2675],\n",
       "        [-0.2484],\n",
       "        [-0.2294],\n",
       "        [-0.2104],\n",
       "        [-0.1913],\n",
       "        [-0.1723],\n",
       "        [-0.1532],\n",
       "        [-0.1342],\n",
       "        [-0.1151],\n",
       "        [-0.0961],\n",
       "        [-0.0771],\n",
       "        [-0.0580],\n",
       "        [-0.0390],\n",
       "        [-0.0199],\n",
       "        [-0.0009],\n",
       "        [ 0.0182],\n",
       "        [ 0.0372],\n",
       "        [ 0.0562],\n",
       "        [ 0.0753],\n",
       "        [ 0.0943],\n",
       "        [ 0.1134],\n",
       "        [ 0.1324],\n",
       "        [ 0.1515],\n",
       "        [ 0.1705],\n",
       "        [ 0.1895],\n",
       "        [ 0.2086],\n",
       "        [ 0.2276]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X) # forward (derdoor jagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7055],\n",
      "        [-0.6864],\n",
      "        [-0.6674],\n",
      "        [-0.6483],\n",
      "        [-0.6293],\n",
      "        [-0.6103],\n",
      "        [-0.5912],\n",
      "        [-0.5722],\n",
      "        [-0.5531],\n",
      "        [-0.5341],\n",
      "        [-0.5150],\n",
      "        [-0.4960],\n",
      "        [-0.4770],\n",
      "        [-0.4579],\n",
      "        [-0.4389],\n",
      "        [-0.4198],\n",
      "        [-0.4008],\n",
      "        [-0.3817],\n",
      "        [-0.3627],\n",
      "        [-0.3437],\n",
      "        [-0.3246],\n",
      "        [-0.3056],\n",
      "        [-0.2865],\n",
      "        [-0.2675],\n",
      "        [-0.2484],\n",
      "        [-0.2294],\n",
      "        [-0.2104],\n",
      "        [-0.1913],\n",
      "        [-0.1723],\n",
      "        [-0.1532],\n",
      "        [-0.1342],\n",
      "        [-0.1151],\n",
      "        [-0.0961],\n",
      "        [-0.0771],\n",
      "        [-0.0580],\n",
      "        [-0.0390],\n",
      "        [-0.0199],\n",
      "        [-0.0009],\n",
      "        [ 0.0182],\n",
      "        [ 0.0372],\n",
      "        [ 0.0562],\n",
      "        [ 0.0753],\n",
      "        [ 0.0943],\n",
      "        [ 0.1134],\n",
      "        [ 0.1324],\n",
      "        [ 0.1515],\n",
      "        [ 0.1705],\n",
      "        [ 0.1895],\n",
      "        [ 0.2086],\n",
      "        [ 0.2276]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    print(model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.L1Loss() # MAE loss is same as L1Loss\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.9071348309516907 | MAE Test Loss: 0.7675976157188416 \n",
      "Epoch: 10 | MAE Train Loss: 0.7919250130653381 | MAE Test Loss: 0.6328878402709961 \n",
      "Epoch: 20 | MAE Train Loss: 0.6767148971557617 | MAE Test Loss: 0.4981774687767029 \n",
      "Epoch: 30 | MAE Train Loss: 0.5615048408508301 | MAE Test Loss: 0.36346712708473206 \n",
      "Epoch: 40 | MAE Train Loss: 0.44629472494125366 | MAE Test Loss: 0.22875675559043884 \n",
      "Epoch: 50 | MAE Train Loss: 0.33108454942703247 | MAE Test Loss: 0.09404630213975906 \n",
      "Epoch: 60 | MAE Train Loss: 0.2158743143081665 | MAE Test Loss: 0.04135196655988693 \n",
      "Epoch: 70 | MAE Train Loss: 0.13913975656032562 | MAE Test Loss: 0.14073064923286438 \n",
      "Epoch: 80 | MAE Train Loss: 0.11635442078113556 | MAE Test Loss: 0.18724334239959717 \n",
      "Epoch: 90 | MAE Train Loss: 0.10718341171741486 | MAE Test Loss: 0.20930823683738708 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    # Put model in training mode (this is the default state of a model)\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass on train data using the forward() method inside \n",
    "    y_pred = model(X_train)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model(X_test)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
