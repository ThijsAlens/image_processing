{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4],\n",
      "         [5, 6]]]) 3 torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor([[[1, 2], [3, 4], [5, 6]]])\n",
    "print(scalar, scalar.ndim, scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 25 15:34:23 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060        Off |   00000000:01:00.0  On |                  N/A |\n",
      "| 32%   30C    P8             N/A /  115W |     651MiB /   8188MiB |     34%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2728      G   /usr/lib/xorg/Xorg                            149MiB |\n",
      "|    0   N/A  N/A      2930      G   /usr/bin/gnome-shell                          127MiB |\n",
      "|    0   N/A  N/A      2973      G   /usr/bin/veyon-server                           2MiB |\n",
      "|    0   N/A  N/A      3072      G   /usr/bin/veyon-worker                           2MiB |\n",
      "|    0   N/A  N/A      4134      G   ...irefox/5134/usr/lib/firefox/firefox        216MiB |\n",
      "|    0   N/A  N/A      5637      G   /usr/bin/nautilus                              14MiB |\n",
      "|    0   N/A  N/A      5879      G   ...erProcess --variations-seed-version        120MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing \n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.6682]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3584], requires_grad=True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "model.weight, model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3584],\n",
       "        [-0.3450],\n",
       "        [-0.3316],\n",
       "        [-0.3183],\n",
       "        [-0.3049],\n",
       "        [-0.2915],\n",
       "        [-0.2782],\n",
       "        [-0.2648],\n",
       "        [-0.2515],\n",
       "        [-0.2381],\n",
       "        [-0.2247],\n",
       "        [-0.2114],\n",
       "        [-0.1980],\n",
       "        [-0.1846],\n",
       "        [-0.1713],\n",
       "        [-0.1579],\n",
       "        [-0.1445],\n",
       "        [-0.1312],\n",
       "        [-0.1178],\n",
       "        [-0.1044],\n",
       "        [-0.0911],\n",
       "        [-0.0777],\n",
       "        [-0.0643],\n",
       "        [-0.0510],\n",
       "        [-0.0376],\n",
       "        [-0.0243],\n",
       "        [-0.0109],\n",
       "        [ 0.0025],\n",
       "        [ 0.0158],\n",
       "        [ 0.0292],\n",
       "        [ 0.0426],\n",
       "        [ 0.0559],\n",
       "        [ 0.0693],\n",
       "        [ 0.0827],\n",
       "        [ 0.0960],\n",
       "        [ 0.1094],\n",
       "        [ 0.1228],\n",
       "        [ 0.1361],\n",
       "        [ 0.1495],\n",
       "        [ 0.1629],\n",
       "        [ 0.1762],\n",
       "        [ 0.1896],\n",
       "        [ 0.2029],\n",
       "        [ 0.2163],\n",
       "        [ 0.2297],\n",
       "        [ 0.2430],\n",
       "        [ 0.2564],\n",
       "        [ 0.2698],\n",
       "        [ 0.2831],\n",
       "        [ 0.2965]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X) # forward (derdoor jagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3584],\n",
      "        [-0.3450],\n",
      "        [-0.3316],\n",
      "        [-0.3183],\n",
      "        [-0.3049],\n",
      "        [-0.2915],\n",
      "        [-0.2782],\n",
      "        [-0.2648],\n",
      "        [-0.2515],\n",
      "        [-0.2381],\n",
      "        [-0.2247],\n",
      "        [-0.2114],\n",
      "        [-0.1980],\n",
      "        [-0.1846],\n",
      "        [-0.1713],\n",
      "        [-0.1579],\n",
      "        [-0.1445],\n",
      "        [-0.1312],\n",
      "        [-0.1178],\n",
      "        [-0.1044],\n",
      "        [-0.0911],\n",
      "        [-0.0777],\n",
      "        [-0.0643],\n",
      "        [-0.0510],\n",
      "        [-0.0376],\n",
      "        [-0.0243],\n",
      "        [-0.0109],\n",
      "        [ 0.0025],\n",
      "        [ 0.0158],\n",
      "        [ 0.0292],\n",
      "        [ 0.0426],\n",
      "        [ 0.0559],\n",
      "        [ 0.0693],\n",
      "        [ 0.0827],\n",
      "        [ 0.0960],\n",
      "        [ 0.1094],\n",
      "        [ 0.1228],\n",
      "        [ 0.1361],\n",
      "        [ 0.1495],\n",
      "        [ 0.1629],\n",
      "        [ 0.1762],\n",
      "        [ 0.1896],\n",
      "        [ 0.2029],\n",
      "        [ 0.2163],\n",
      "        [ 0.2297],\n",
      "        [ 0.2430],\n",
      "        [ 0.2564],\n",
      "        [ 0.2698],\n",
      "        [ 0.2831],\n",
      "        [ 0.2965]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    print(model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.L1Loss() # MAE loss is same as L1Loss\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.6707576513290405 | MAE Test Loss: 0.6731709241867065 \n",
      "Epoch: 10 | MAE Train Loss: 0.555547833442688 | MAE Test Loss: 0.5384610295295715 \n",
      "Epoch: 20 | MAE Train Loss: 0.4403378367424011 | MAE Test Loss: 0.40375107526779175 \n",
      "Epoch: 30 | MAE Train Loss: 0.32512789964675903 | MAE Test Loss: 0.2690412104129791 \n",
      "Epoch: 40 | MAE Train Loss: 0.20991790294647217 | MAE Test Loss: 0.13433125615119934 \n",
      "Epoch: 50 | MAE Train Loss: 0.09470794349908829 | MAE Test Loss: 0.008356565609574318 \n",
      "Epoch: 60 | MAE Train Loss: 0.03896244615316391 | MAE Test Loss: 0.07178118079900742 \n",
      "Epoch: 70 | MAE Train Loss: 0.033962421119213104 | MAE Test Loss: 0.07603313028812408 \n",
      "Epoch: 80 | MAE Train Loss: 0.03046739101409912 | MAE Test Loss: 0.07050827145576477 \n",
      "Epoch: 90 | MAE Train Loss: 0.02702857181429863 | MAE Test Loss: 0.062235765159130096 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    # Put model in training mode (this is the default state of a model)\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass on train data using the forward() method inside \n",
    "    y_pred = model(X_train)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model(X_test)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().cpu().numpy())\n",
    "            test_loss_values.append(test_loss.detach().cpu().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0551)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
