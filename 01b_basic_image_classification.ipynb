{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a855255f-41de-43de-9698-5f5b8580e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "#keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9914e-f12c-4063-8b7c-a3eddf1f48b4",
   "metadata": {},
   "source": [
    "# Basic image classification\n",
    "\n",
    "In this notebook, we are going to train a basic CNN on the MNIST dataset, a small dataset that contains handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac6cfb-f67d-4a80-bceb-dcaa84ae83c9",
   "metadata": {},
   "source": [
    "## Implementing a Simple CNN\n",
    "\n",
    "You can use [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) to create a single convolutional layer in PyTorch. Some of its interesting arguments are:\n",
    "\n",
    "- `in_channels`: the number of channels in the input tensor. When the input is an RGB image, this is `3`. For a single-channel gray scale image, this is `1`. Note that each convolution filter in the layer will have this amount of channels as the filter needs to cover the *entire depth* of the input.\n",
    "- `out_channels`: the number of convolution filters that this layer has. Each filter will produce a new channel in the output. As such, if another `nn.Conv2d()` takes the output of this layer as its input, that layer's `in_channels` should be set to this layer's `out_channels`.\n",
    "- `kernel_size`: the height and width of the convolution filters. If this is a single integer, it will be used for both the height and the width (i.e., square filters).\n",
    "- `stride`: the stride (step size) of the convolution operation (default: `1`).\n",
    "- `padding`: the amount of padding to add to the input (default: `0`). *Padding* is a border of black pixels that is added around the input image. This allows more of the convolution operation to be applied to the pixels at the edge of the image and can avoid the output resolution to shrink w.r.t. the input resolution. When `padding` is set to `1`, a black border of a single pixel wide will be added at each image edge.\n",
    "\n",
    "Apart from convolutional layers, a CNN also typically contains *pooling layers*. Similar to conv layers, a pooling layer uses a sliding window to operate on its input. Instead of computing an inner product, however, the pooling window **aggregates** the underlying values, e.g., by computing the *maximum* or *average* value. For example:\n",
    "\n",
    "- [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) applies max pooling.\n",
    "- [`nn.AvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) applies average pooling.\n",
    "\n",
    "Just like `nn.Conv2d()`, these pooling layers take `kernel_size`, `stride` (default: `1`) and `padding` (default: `0`) as an argument.\n",
    "\n",
    "The pooling layers also have *adaptive* equivalents: [`nn.AdaptiveMaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html) and [`nn.AdaptiveAvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html). These adaptive layers produce an **output of a fixed, predefined width and height no matter the input size** (the number of channels stays the same). This is in contrast with regular pooling layers, where the output size depends on the input size.\n",
    "\n",
    "There are multiple ways to tie layers together into a network. One of the easiest ways is through [`nn.Sequential()`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html). You can check out the corresponding documentation for more info and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3b4-5b9d-40b7-9af9-dc2f1ac5c0d1",
   "metadata": {},
   "source": [
    "Create a neural network with the following layers:\n",
    "\n",
    "- A `Conv2d` layer with 64 5x5 filters, stride 2 and padding 2\n",
    "- An `AdaptiveAvgPool2d` layer that outputs width and height 1\n",
    "- A `Flatten` layer that flattens it input to shape `(N,64)`\n",
    "- A `Linear` (i.e., fully-connected) layer that transforms its input to 10 output values, corresponding to the 10 classes in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f168883c-c738-45e9-b37f-3c272596955c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Conv2d.__init__() missing 3 required positional arguments: 'in_channels', 'out_channels', and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Conv2d.__init__() missing 3 required positional arguments: 'in_channels', 'out_channels', and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "nn.Conv2d(in_channels=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228a71e-1b23-4d2b-9052-e3947121fb5f",
   "metadata": {},
   "source": [
    "Let's try and train our model! But first, we'll need two more things:\n",
    "\n",
    "1. Data to train on\n",
    "2. Training logic\n",
    "\n",
    "We'll define both in the following two sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5500c18-cc57-4b8e-917e-78681fa3fda4",
   "metadata": {},
   "source": [
    "## Obtaining the Data for Batch Training\n",
    "\n",
    "In the cell below, we have defined a function that returns all images and the corresponding labels for a subset of the MNIST dataset (i.e., the training set when `train=True`, the validation set when `train=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e4c147-d095-4c06-80dc-813b69352a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def get_mnist(train=True):\n",
    "    mnist = MNIST(root='../data', download=True, train=train)\n",
    "    data = ((mnist.data.float()[:, None, :, :] / 255))\n",
    "    half_len = len(data) // 2\n",
    "\n",
    "    return data[:half_len], mnist.targets[:half_len]\n",
    "\n",
    "#keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa1255-ad66-4a86-85b5-b793f7f8c8da",
   "metadata": {},
   "source": [
    "Use this function to create the training and validation set. Inspect the shapes of the returned tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95886b8b-f632-4d5f-85e3-a9054e9c78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0680d-6f9c-44aa-8b9c-970b2b3ef273",
   "metadata": {},
   "source": [
    "## Defining the Training Loop\n",
    "\n",
    "Now that we have our first model and data ready, we can define our training loop! We have already implemented it below. Read through it, and **ensure that you understand what's happening**. The function **returns three lists**: the first one contains the training losses, the second one the validation losses and the third one the validation accuracies throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83818b2e-295a-4e4c-8cb7-46eb6715993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, x_train, y_train, x_val, y_val, optimizer, loss_fn, num_epochs):\n",
    "    \"\"\"\n",
    "    Train a classifier using batch gradient descent.\n",
    "\n",
    "    Args:\n",
    "        model: The classification model.\n",
    "        x_train: A Tensor containing the training images.\n",
    "        y_train: A Tensor with the true label of each training image.\n",
    "        x_val: A Tensor containing the validation images.\n",
    "        y_val: A Tensor with the true label of each validation image.\n",
    "        optimizer: The optimizer.\n",
    "        loss_fn: The loss function.\n",
    "        num_epochs: The number of epochs to train.\n",
    "    \"\"\"\n",
    "    train_loss_curve = []\n",
    "    val_loss_curve = []\n",
    "    val_acc_curve = []\n",
    "\n",
    "    # Iterate over the epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Put model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        # Backpropagate + optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Append to train loss curve\n",
    "        train_loss_curve.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        # Put model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Compute predictions (without storing gradients)\n",
    "        with torch.inference_mode():\n",
    "            y_pred = model(x_val)\n",
    "\n",
    "        # Compute validation loss\n",
    "        loss = loss_fn(y_pred, y_val)\n",
    "        val_loss_curve.append(loss.cpu().numpy())\n",
    "\n",
    "        # Compute validation accuracy\n",
    "        acc = (y_val == y_pred.argmax(dim=1)).float().mean()\n",
    "        val_acc_curve.append(acc.cpu().numpy())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Log losses\n",
    "            print(f\"Train loss at epoch {epoch}: {train_loss_curve[-1]:.4f}\")\n",
    "            print(f\"Validation loss after epoch {epoch}: {val_loss_curve[-1]:.4f}\")\n",
    "            print(f\"Validation accuracy after epoch {epoch}: {val_acc_curve[-1]:.4f}\")\n",
    "            print()\n",
    "\n",
    "    return np.array(train_loss_curve), np.array(val_loss_curve), np.array(val_acc_curve)\n",
    "#keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486c3b3-3165-4c25-add0-3e57f4bd788a",
   "metadata": {},
   "source": [
    "## Running the Training\n",
    "\n",
    "Time to train our home-grown CNN! ðŸª´\n",
    "\n",
    "- Define a loss function for training classification (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions)). Use cross entropy loss.\n",
    "- Create an optimizer (see [here](https://pytorch.org/docs/stable/optim.html)). Use the Adam algorithm.\n",
    "- Call `train_classifier()`, and store the returned training and validation curves. Train for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b11b7c-b818-4a61-af5c-d9d63c30d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0b05e-18af-4e56-b174-2e50906f8d9b",
   "metadata": {},
   "source": [
    "You might notice that the training progresses rather slowly. Feel free to cancel it. **Move all data, as well as the model to the GPU** by calling [`.to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html), with `device` set to `'cuda'` if CUDA is available, else `'cpu'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ffdbd7f-8ee4-47b2-abad-bff964d3f457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c198ca-6ca6-4c23-9718-ac080d03761d",
   "metadata": {},
   "source": [
    "Redefine the optimizer (since our old optimizer still holds the cpu parameters) and call `train_classifier` again. **Do you notice a speed-up?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd884da8-2fad-484a-9ed7-ce056b61239e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4776869-dc46-4d8b-8144-155c31af775a",
   "metadata": {},
   "source": [
    "Plot the train loss curve, validation loss curve and the validation accuracy curve using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aa210-079c-4d1f-91c7-07073c6164aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09397d98-4834-45b5-8c90-67e2e7facce2",
   "metadata": {},
   "source": [
    "## Improve the model\n",
    "\n",
    "Create a new model based on the previous one, but add an extra convolutional layer after the first one with the same hyper parameters. Make sure the number of input channels of the new layer matches the number of output channels of its predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8f4d01-6f6c-4e57-ae5a-5a0c5f221c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c6401-1263-46e2-bbfb-132e46838460",
   "metadata": {},
   "source": [
    "Move the new model to GPU, redefine the optimizer and train it. Plot the train loss curve, validation loss curve and the validation accuracy curve using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef79253-896f-499d-b108-564b25488fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ead06-ee15-4d03-97f6-56cd507ea43a",
   "metadata": {},
   "source": [
    "Compare the loss curves of the new model with the first one.\n",
    "Create a new model  based on the previous one, but wow **insert a `ReLU` layer after each convolution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81cfdb34-b1c0-44bc-bd80-7fcc6f6d0582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4960612-52ba-4d4d-9a4a-0fa68acd72b3",
   "metadata": {},
   "source": [
    "Move the new model to GPU, redefine the optimizer and train it. Plot the train loss curve, validation loss curve and the validation accuracy curve using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbfdc5-dcb5-49f4-a793-715581f68670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d3efe-43d2-46f7-bb8e-a7b832b9b25c",
   "metadata": {},
   "source": [
    "Again compare the loss curves of this model with the previous two. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff99554-8f2b-42ba-81da-1c88d661b3c7",
   "metadata": {},
   "source": [
    "## Inspecting the results\n",
    "\n",
    "Pass all validation samples through your best model and store the results in a variable `y_pred`. Hint: look at the validation routine inside `train_classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce239e6-7f19-435a-bad3-ecba1d8814c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f18b5-d892-477a-b370-0122a5df90bc",
   "metadata": {},
   "source": [
    "Now write code to **select a random sample from the validation set**. **Visualize the sample** using Matplotlib and put the **predicted label and true label in the title** of the figure. Hint: use the index of the neuron with the largest output value as prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e467e37-6011-41f6-8a06-639f49f4229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1891fd-d710-4a6a-9c42-31aef3115e75",
   "metadata": {},
   "source": [
    "Use [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [`sklearn.metrics.ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) to visualize the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... WRITE YOUR CODE HERE ... #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
